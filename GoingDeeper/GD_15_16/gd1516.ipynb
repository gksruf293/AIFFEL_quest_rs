{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3fb2f4ed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch version:1.12.1\n",
      "Cuda version: 11.3\n",
      "transformers version: 4.28.0\n",
      "GPU 사용 가능여부: True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import transformers\n",
    "\n",
    "print(\"Torch version:{}\".format(torch.__version__)) # Torch version:1.12.1\n",
    "print(\"Cuda version: {}\".format(torch.version.cuda)) # Cuda version: 11.3\n",
    "print(\"transformers version: {}\".format(transformers.__version__)) # transformers 4.28.0\n",
    "print(\"GPU 사용 가능여부: {}\".format(torch.cuda.is_available()))\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# 현재 스크립트의 위치 기준으로 상위 디렉토리 추가\n",
    "sys.path.append(os.path.abspath(\"colossalai_ChatGPT_230319\"))\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import pandas as pd\n",
    "import numpy\n",
    "\n",
    "from abc import ABC\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from chatgpt.trainer.strategies import NaiveStrategy, Strategy\n",
    "from torch.optim import Optimizer\n",
    "from chatgpt.trainer.utils import is_rank_0\n",
    "\n",
    "from transformers import GPT2LMHeadModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9aef457",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model_name = \"skt/kogpt2-base-v2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a6d76da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3+5 =?? (... ).\n",
      "그런데 이 녀석이 뭔지 알 수 없는 건지...\n",
      "아무튼 이녀석의 정체는 닌자 거북이.</d> 2017년 12월 11일부터 2018년 12월 31일까지 방영된 SBS 월화드라마.\n",
      "2017년 11월 12일부터 2020년 1월 15일까지 매주 금요일 오후 7시 40분에 방송된다.</d> ##당 내부 선거가 아닌 대한민국 선출직 공직자 선거 결과만 기록한다.\n",
      "선거종류 득표수 ( 득표율 ) 비고 1996 민주통합당 낙선 ( 1위 )\n",
      "제19대 국회의원 선거 ( 경기도 수원시\n"
     ]
    }
   ],
   "source": [
    "input_txt = \"3+5 = ?\"\n",
    "\n",
    "tokens = tokenizer(input_txt).tokens()\n",
    "input_ids = tokenizer(input_txt, return_tensors=\"pt\")[\"input_ids\"].to(device)\n",
    "max_length = 128\n",
    "\n",
    "output_beam = model.generate(input_ids, max_length=max_length, num_beams=7, no_repeat_ngram_size=2,\n",
    "                             do_sample=True, top_p=0.90)\n",
    "print(tokenizer.decode(output_beam[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1de8dc1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'prompt': '불고기용 고기 한우에요?',\n",
       "  'completion': \"'저는 인공지능 챗봇이며, 직접적으로 식품에 관한 정보를 가지고 있지 않습니다. 하지만 일반적으로 불고기용 고기는 한우, 쇠고기, 돼지고기 등 다양한 종류의 고기를 사용합니다. 하지만 한우는 대표적인 고급 육류로 알려져 있기 때문에, 한우를 사용하는 경우도 많습니다. 알러지나 개별 건강 상태에 따라 다를 수 있으니 충분한 정보 수집 후에 선택해 주시기 바랍니다.\",\n",
       "  'tokens': 193},\n",
       " {'prompt': '쓰던 앱이 유료로 전환됐어',\n",
       "  'completion': \"'어떤 앱인지 모르기 때문에 정확한 답변을 드리기 어렵습니다. 하지만, 일반적으로 유료 전환된 앱은 기존 무료 앱에서 추가적인 기능이나 서비스를 제공하는 경우가 많습니다. 이 경우, 유료 전환 이전 가격이 매우 저렴하거나 무료인 경우가 많으므로, 앱을 계속 사용하려면 추가적인 비용을 지불해야 할 수 있습니다. 하지만, 유료 전환 이후에는 기존 사용자 또는 새로운 사용자 모두가 추가 기능과 높은 품질의 서비스를 이용할 수 있게 됩니다. 따라서, 앱 개발자는 유료 모델로 전환함으로써 앱의 수익을 증가시키고 더 나은 서비스를 제공할 수 있습니다.\",\n",
       "  'tokens': 288},\n",
       " {'prompt': '여친이랑 다툼',\n",
       "  'completion': \"'저는 인공지능이기 때문에 여친과의 다툼에 대해서는 조언을 드릴 수는 없습니다. 하지만 다투게 되면 상대방의 말을 경청하는 태도와 서로의 감정을 존중하는 것이 중요합니다. 논리적이고 차분한 대화를 통해 문제를 해결해보세요. 그리고 서로를 이해하고 서로의 의견을 수용하는 것이 중요합니다.\",\n",
       "  'tokens': 153}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json \n",
    "data_path_1_SFT = './data_kochatgpt/kochatgpt_1_SFT.jsonl' \n",
    "with open(data_path_1_SFT, \"r\", encoding='utf-8-sig') as json_file:\n",
    "    list_data_dict = json.load(json_file)\n",
    "\n",
    "print(len(list_data_dict))\n",
    "list_data_dict[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c5a368f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10220\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'prompt': '번디는 자신이 탐정잡지, 범죄소설 그리고 성범죄 관련 실제 범죄 다큐멘터리들을 탐독했다고 누구에게 말했나?',\n",
       "  'completion_0': 'Allow me to answer your question. I know that you are curious about me.',\n",
       "  'completion_1': '번디는 다양한 인터뷰자들과 뉴스홍보 담당자들과의 면담 때 밝혔다.',\n",
       "  'completion_2': '라이언에게 말했다.',\n",
       "  'ranking': [2, 1, 0]},\n",
       " {'prompt': '개포주공아파트는 몇 단지로 이루어져 있나?',\n",
       "  'completion_0': '개포주공아파트는 다섯 단지로 이루어져 있습니다.',\n",
       "  'completion_1': '이날 목송에서 구글상위노',\n",
       "  'completion_2': '개포주공아파트는 총 27개 단지로 이루어져 있습니다.',\n",
       "  'ranking': [2, 0, 1]},\n",
       " {'prompt': '김영삼의 후보 시절 지역표심을 겨냥한 발언을 문제삼은 후보는?',\n",
       "  'completion_0': 'The diameter of the Metallic domain is bigger than the Hyperonic domain.',\n",
       "  'completion_1': '이 질문은 조금 불분명합니다. 김영삼 대통령이 후보 시절에 어떤 발언을 했고, 누가 그 발언을 문제삼았는지에 따라 답이 다를 수 있습니다.\\\\n\\\\n만약 김영삼 대통령이 후보 시절에 지역표심을 겨냥한 발언을 했다는 가정하에, 그 발언을 문제삼은 후보가 누구였는지를 대답하자면, 그 답은 이화선 당시 민주당 대통령 후보가 될 것입니다. 1992년 총선 때, 김영삼 대선후보는 \"집값이 오른 노량진역 부근의 부동산 가격은 세월호 폭침 후 \\\\\\'강남 도시재생\\\\\\' 일환으로 상승했다\"는 발언을 했습니다. 하지만 이화선 후보는 이 발언을 \"전국적으로 경제적 발전이 이루어지지 않은 지방민의 마음을 멀리해지려는 무례한 발언\"이라고 비판하며 문제삼았습니다.\\\\n\\\\n하지만, 이 질문을 답변하는 데 있어서 보다 명확한 정보가 있으면 답변을 보완할 수 있습니다.',\n",
       "  'completion_2': '김영삼의 후보 시절에 지역표심을 겨냥한 발언은 대통령 당선 전까지 대한민국 정부가 추구하고 있는 민주주의 광범위하게 확립과 보수의 사상을 이어가는 데 있어 지역경제 발전과 공공서비스 신속 개선을 위해 합리적인 국가 정책에 따르는 방향성을 제시하고 있습니다.',\n",
       "  'ranking': [1, 2, 0]}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path_2_RM = './data_kochatgpt/kochatgpt_2_RM.jsonl'\n",
    "with open(data_path_2_RM, \"r\", encoding='utf-8-sig') as json_file:\n",
    "    list_data_dict = json.load(json_file)\n",
    "\n",
    "print(len(list_data_dict))\n",
    "list_data_dict[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f76877",
   "metadata": {},
   "source": [
    "# SFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "447c8886",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.optim import Adam\n",
    "from datasets import load_dataset\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from copy import deepcopy\n",
    "import copy\n",
    "import logging\n",
    "import json\n",
    "from dataclasses import dataclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "45605d84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT2TokenizerFast(name_or_path='skt/kogpt2-base-v2', vocab_size=51200, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '</s>', 'eos_token': '</s>', 'unk_token': '</s>', 'pad_token': '</s>'}, clean_up_tokenization_spaces=True)\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained('skt/kogpt2-base-v2')\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    'skt/kogpt2-base-v2', bos_token='</s>', eos_token='</s>', unk_token='</s>', pad_token='</s>',\n",
    "    padding_side=\"right\",\n",
    "    model_max_length=512,\n",
    ")\n",
    "\n",
    "print(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c2e38111",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, Dict, Sequence\n",
    "\n",
    "class SFT_dataset(Dataset):\n",
    "\n",
    "    def __init__(self, data_path_1_SFT: str, tokenizer: transformers.PreTrainedTokenizer, verbose=False):\n",
    "        super(SFT_dataset, self).__init__()\n",
    "        logging.warning(\"Loading data...\")\n",
    "\n",
    "        pattern_instruction = 'prompt'  # instruction\n",
    "        pattern_output = 'completion'  # response\n",
    "\n",
    "        with open(data_path_1_SFT, \"r\", encoding='utf-8-sig') as json_file:\n",
    "            list_data_dict = json.load(json_file)\n",
    "\n",
    "        PROMPT_DICT = {\n",
    "            \"prompt_input\": (\n",
    "                \"### Instruction(명령어):\\n{prompt}\\n\\n### Response(응답):\"\n",
    "            )\n",
    "        }\n",
    "\n",
    "        prompt_input = PROMPT_DICT[\"prompt_input\"]\n",
    "\n",
    "        sources = []\n",
    "        for example in list_data_dict:\n",
    "            tmp = prompt_input.format_map(example)\n",
    "            sources.append(tmp)\n",
    "\n",
    "        targets = []\n",
    "        for example in list_data_dict:\n",
    "            targets.append(f\"{example[pattern_output]}{tokenizer.eos_token}\")\n",
    "        examples = [s + t for s, t in zip(sources, targets)]\n",
    "\n",
    "        sources_tokenized = self._tokenize_fn(sources, tokenizer)  # source\n",
    "        examples_tokenized = self._tokenize_fn(examples, tokenizer)  # source + target\n",
    "\n",
    "        input_ids = examples_tokenized[\"input_ids\"]\n",
    "        labels = copy.deepcopy(input_ids)\n",
    "        for label, source_len in zip(labels, sources_tokenized[\"input_ids_lens\"]):\n",
    "            label[:source_len] = -100\n",
    "\n",
    "        data_dict = dict(input_ids=input_ids, labels=labels)\n",
    "\n",
    "        self.input_ids = data_dict[\"input_ids\"]\n",
    "        self.labels = data_dict[\"labels\"]\n",
    "        logging.warning(\"Loading data done!!: %d\"%(len(self.labels)))\n",
    "\n",
    "\n",
    "    def _tokenize_fn(self, strings: Sequence[str], tokenizer: transformers.PreTrainedTokenizer) -> Dict:\n",
    "        tokenized_list = [\n",
    "            tokenizer(\n",
    "                text,\n",
    "                return_tensors=\"pt\",\n",
    "                padding=\"longest\",\n",
    "                max_length=tokenizer.model_max_length,\n",
    "                truncation=True,\n",
    "            )\n",
    "            for text in strings\n",
    "        ]\n",
    "        input_ids = labels = [tokenized.input_ids[0] for tokenized in tokenized_list]\n",
    "        input_ids_lens = labels_lens = [\n",
    "            tokenized.input_ids.ne(tokenizer.pad_token_id).sum().item() for tokenized in tokenized_list\n",
    "        ]\n",
    "        return dict(\n",
    "            input_ids=input_ids,\n",
    "            labels=labels,\n",
    "            input_ids_lens=input_ids_lens,\n",
    "            labels_lens=labels_lens,\n",
    "        )\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "\n",
    "    def __getitem__(self, i) -> Dict[str, torch.Tensor]:\n",
    "        return dict(input_ids=self.input_ids[i], labels=self.labels[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0578eb47",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class DataCollatorForSupervisedDataset(object): \n",
    "\n",
    "    tokenizer: transformers.PreTrainedTokenizer\n",
    "\n",
    "    def __call__(self, instances: Sequence[Dict]) -> Dict[str, torch.Tensor]:\n",
    "        input_ids, labels = tuple([instance[key] for instance in instances] for key in (\"input_ids\", \"labels\"))\n",
    "        input_ids = torch.nn.utils.rnn.pad_sequence(\n",
    "            input_ids, batch_first=True, padding_value=self.tokenizer.pad_token_id\n",
    "        )\n",
    "        labels = torch.nn.utils.rnn.pad_sequence(labels, batch_first=True, padding_value= -100)\n",
    "        return dict(\n",
    "            input_ids=input_ids,\n",
    "            labels=labels,\n",
    "            attention_mask=input_ids.ne(self.tokenizer.pad_token_id),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f7ac682b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Loading data...\n",
      "WARNING:root:Loading data done!!: 12000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input : tensor([  739,   378,   378,   378, 14659, 13394, 37091, 10651,   383, 25841,\n",
      "         8006, 14914,   375,  7673, 20479,  8091, 22311,  9036, 30902, 13675,\n",
      "          375,   378,   378,   378, 41951,   454,  9549, 20549,   383,  8142,\n",
      "         7192, 14914,   382, 37767, 13753,  8263,  7166,   739,  8352,  7659,\n",
      "         9594, 25585, 13600,  8022,  9378, 11532,  9887, 11218,  9111, 16691,\n",
      "        10351, 10561,  9128, 20479,  8091,  9065,  9446,  9036, 28420, 26521,\n",
      "        10163, 26367,  6958,  9030,  9882, 12317, 25882,  9209, 37194, 10351,\n",
      "         9036, 12168, 10529, 15989,  9719, 15434, 10552, 11188, 13362,  9036,\n",
      "        15805, 11300, 11846,  9146, 16691,  9181,  7397, 15806, 13480, 11342,\n",
      "        17596,  9161, 19996,  9025, 25006, 18595,  9966, 12592, 10751, 11814,\n",
      "         8711,  9046, 12450,  9117,  7377, 12521,     1])\n",
      "output: tensor([ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,   382, 37767, 13753,  8263,  7166,   739,  8352,  7659,\n",
      "         9594, 25585, 13600,  8022,  9378, 11532,  9887, 11218,  9111, 16691,\n",
      "        10351, 10561,  9128, 20479,  8091,  9065,  9446,  9036, 28420, 26521,\n",
      "        10163, 26367,  6958,  9030,  9882, 12317, 25882,  9209, 37194, 10351,\n",
      "         9036, 12168, 10529, 15989,  9719, 15434, 10552, 11188, 13362,  9036,\n",
      "        15805, 11300, 11846,  9146, 16691,  9181,  7397, 15806, 13480, 11342,\n",
      "        17596,  9161, 19996,  9025, 25006, 18595,  9966, 12592, 10751, 11814,\n",
      "         8711,  9046, 12450,  9117,  7377, 12521,     1])\n"
     ]
    }
   ],
   "source": [
    "train_dataset = SFT_dataset(data_path_1_SFT='./data_kochatgpt/kochatgpt_1_SFT.jsonl', tokenizer=tokenizer)\n",
    "data_collator = DataCollatorForSupervisedDataset(tokenizer=tokenizer)\n",
    "\n",
    "print('input : %s'%train_dataset.input_ids[0])\n",
    "print('output: %s'%train_dataset.labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a1b2bf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input : ### Instruction(명령어):\n",
      "불고기용 고기 한우에요?\n",
      "\n",
      "### Response(응답):'저는 인공지능 챗봇이며, 직접적으로 식품에 관한 정보를 가지고 있지 않습니다. 하지만 일반적으로 불고기용 고기는 한우, 쇠고기, 돼지고기 등 다양한 종류의 고기를 사용합니다. 하지만 한우는 대표적인 고급 육류로 알려져 있기 때문에, 한우를 사용하는 경우도 많습니다. 알러지나 개별 건강 상태에 따라 다를 수 있으니 충분한 정보 수집 후에 선택해 주시기 바랍니다.</s>\n",
      "output: '저는 인공지능 챗봇이며, 직접적으로 식품에 관한 정보를 가지고 있지 않습니다. 하지만 일반적으로 불고기용 고기는 한우, 쇠고기, 돼지고기 등 다양한 종류의 고기를 사용합니다. 하지만 한우는 대표적인 고급 육류로 알려져 있기 때문에, 한우를 사용하는 경우도 많습니다. 알러지나 개별 건강 상태에 따라 다를 수 있으니 충분한 정보 수집 후에 선택해 주시기 바랍니다.</s>\n"
     ]
    }
   ],
   "source": [
    "# input은 그대로\n",
    "print('input : %s' % tokenizer.decode(train_dataset.input_ids[0]))\n",
    "\n",
    "# output은 ignore_index 제거 후 디코딩\n",
    "label_ids = [id for id in train_dataset.labels[0] if id != -100]\n",
    "print('output: %s' % tokenizer.decode(label_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f589166e",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./test\",\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=10,\n",
    "    per_device_train_batch_size=2,\n",
    "    per_device_eval_batch_size=2,\n",
    "    gradient_accumulation_steps=4,\n",
    "    warmup_steps=5,\n",
    "    prediction_loss_only=True,\n",
    "    fp16 = True\n",
    "    )\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=train_dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "89078d22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'|===========================================================================|\\n|                  PyTorch CUDA memory summary, device ID 0                 |\\n|---------------------------------------------------------------------------|\\n|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\\n|===========================================================================|\\n|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\\n|---------------------------------------------------------------------------|\\n| Allocated memory      |  501217 KB |  701897 KB |   16713 MB |   16224 MB |\\n|       from large pool |  488448 KB |  689082 KB |   13740 MB |   13263 MB |\\n|       from small pool |   12769 KB |   84866 KB |    2972 MB |    2960 MB |\\n|---------------------------------------------------------------------------|\\n| Active memory         |  501217 KB |  701897 KB |   16713 MB |   16224 MB |\\n|       from large pool |  488448 KB |  689082 KB |   13740 MB |   13263 MB |\\n|       from small pool |   12769 KB |   84866 KB |    2972 MB |    2960 MB |\\n|---------------------------------------------------------------------------|\\n| GPU reserved memory   |     840 MB |     840 MB |     840 MB |       0 B  |\\n|       from large pool |     750 MB |     750 MB |     750 MB |       0 B  |\\n|       from small pool |      90 MB |      90 MB |      90 MB |       0 B  |\\n|---------------------------------------------------------------------------|\\n| Non-releasable memory |   55838 KB |  141957 KB |   17184 MB |   17130 MB |\\n|       from large pool |   54272 KB |  140403 KB |   13908 MB |   13855 MB |\\n|       from small pool |    1566 KB |   29673 KB |    3276 MB |    3274 MB |\\n|---------------------------------------------------------------------------|\\n| Allocations           |     174    |     272    |   59846    |   59672    |\\n|       from large pool |      50    |     126    |    6211    |    6161    |\\n|       from small pool |     124    |     219    |   53635    |   53511    |\\n|---------------------------------------------------------------------------|\\n| Active allocs         |     174    |     272    |   59846    |   59672    |\\n|       from large pool |      50    |     126    |    6211    |    6161    |\\n|       from small pool |     124    |     219    |   53635    |   53511    |\\n|---------------------------------------------------------------------------|\\n| GPU reserved segments |      76    |      76    |      76    |       0    |\\n|       from large pool |      31    |      31    |      31    |       0    |\\n|       from small pool |      45    |      45    |      45    |       0    |\\n|---------------------------------------------------------------------------|\\n| Non-releasable allocs |      22    |      66    |   24580    |   24558    |\\n|       from large pool |      19    |      34    |    2927    |    2908    |\\n|       from small pool |       3    |      50    |   21653    |   21650    |\\n|---------------------------------------------------------------------------|\\n| Oversize allocations  |       0    |       0    |       0    |       0    |\\n|---------------------------------------------------------------------------|\\n| Oversize GPU segments |       0    |       0    |       0    |       0    |\\n|===========================================================================|\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.memory_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "76366b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.gradient_checkpointing_enable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c97063a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='15000' max='15000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [15000/15000 1:40:32, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>2.959200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>2.810200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>2.771300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>2.245900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>2.277600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>2.287300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>1.819900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>1.892100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>1.900500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>1.508700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>1.538000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>1.588800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>1.224300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>1.289100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>1.309300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>1.023700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>1.065600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>1.076800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>0.866600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.872800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10500</td>\n",
       "      <td>0.900900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.729500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11500</td>\n",
       "      <td>0.750800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.756600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12500</td>\n",
       "      <td>0.635700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>0.640600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13500</td>\n",
       "      <td>0.641800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>0.556600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14500</td>\n",
       "      <td>0.569900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>0.579200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.train()\n",
    "model.save_pretrained('./output_1_SFT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0384ec2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/transformers/generation/utils.py:1219: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### Instruction(명령어):\n",
      "불고기용 고기 한우에요?\n",
      "\n",
      "### Response(응답):'저는 인공지능 어시스턴트이기 때문에 실제 매장에 대한 정보는 가지고 있지 않습니다. 하지만 일반적으로 불고기용 고기는 한우, 쇠고기, 돼지고기 등 다양한 종류의 고기를 사용합니다. 따라서 한우의 경우 한우, 쇠고기의 경우 한우를 사용하는 경우가 많습니다. 참고: 참고: \"불고기용\n",
      "\n",
      "### Instruction(명령어):\n",
      "리처드 닉슨이 43대 부통령직을 수행한 년도는?\n",
      "\n",
      "### Response(응답):'1953년입니다. 리처드 닉슨은 47대 부통령직을 수행했습니다.\\n\\n1953년 대선 캠프 도중 대통령 후보인 드와이트 D. 아이젠하워와 부통령 후보로 출마할 때 닉슨은 부통령 후보로 출마한 리처드 니콜슨을 지지하며 대선 캠프에서 중요한 역할을\n",
      "\n",
      "### Instruction(명령어):\n",
      "시카고 오헤어 국제공항은 어디에 있어?\n",
      "\n",
      "### Response(응답):'시카고 오 헤어 국제공항은 미국 일리노이 주 시카고에 위치해 있습니다.: DOMY (Department of Okay): Michael Olivery James:\\n\\nCould you please translation\n",
      "\n",
      "### Instruction(명령어):\n",
      "오늘 미세먼지 어때?\n",
      "\n",
      "### Response(응답):'미세먼지 농도는 어제와 비교해서 개선되었지만 아직도 나쁜 수준이며, 마스크 착용과 실외 활동 자제를 권장합니다. 외출 후에는 반드시 마스크를 착용하시는 것이 좋습니다. 참고용으로만 활용하시면 더 나은 미세먼지 농도를 확인할 수 있습니다. 참고용으로는 미세먼지 측정소에서\n"
     ]
    }
   ],
   "source": [
    "generator = pipeline('text-generation', model='./output_1_SFT', tokenizer=tokenizer)\n",
    "\n",
    "generation_args = dict(   \n",
    "    num_beams=4,\n",
    "    repetition_penalty=2.0,\n",
    "    no_repeat_ngram_size=4,\n",
    "    eos_token_id=375, # \\n   \n",
    "    max_new_tokens=64,\n",
    "    do_sample=True,\n",
    "    top_k=50,\n",
    "    early_stopping=True\n",
    ")\n",
    "\n",
    "PROMPT_DICT = {\n",
    "    \"prompt_input\": (\n",
    "        \"### Instruction(명령어):\\n{prompt}\\n\\n### Response(응답):\"\n",
    "    )\n",
    "}\n",
    "\n",
    "list_prompt = ['불고기용 고기 한우에요?',\n",
    "               '리처드 닉슨이 43대 부통령직을 수행한 년도는?',\n",
    "               '시카고 오헤어 국제공항은 어디에 있어?',\n",
    "               '오늘 미세먼지 어때?']\n",
    "\n",
    "list_prompt = [PROMPT_DICT['prompt_input'].format_map({'prompt' : tmp}) for tmp in list_prompt]\n",
    "\n",
    "list_result = generator(list_prompt, **generation_args)   \n",
    "for prompt, result in zip(list_prompt, list_result):\n",
    "    print()\n",
    "    print((result[0]['generated_text']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82195f22",
   "metadata": {},
   "source": [
    "# RM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f4f27ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6cf47f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from typing import Optional\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from chatgpt.dataset import RewardDataset\n",
    "from chatgpt.models.base import RewardModel\n",
    "from chatgpt.trainer import RewardModelTrainer\n",
    "from chatgpt.trainer.strategies import NaiveStrategy\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, AutoModel, AutoConfig\n",
    "from transformers.models.gpt2.configuration_gpt2 import GPT2Config\n",
    "from transformers.models.gpt2.modeling_gpt2 import GPT2Model\n",
    "import loralib as lora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "695fd919",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPTRM_custom(RewardModel):\n",
    "\n",
    "    def __init__(self,\n",
    "                 pretrained: Optional[str] = None,\n",
    "                 config: Optional[GPT2Config] = None,\n",
    "                 checkpoint: bool = False,\n",
    "                 lora_rank: int = 0,\n",
    "                 lora_train_bias: str = 'none',\n",
    "                 tokenizer=None) -> None:\n",
    "        if pretrained is not None:\n",
    "            model = GPT2Model.from_pretrained(pretrained)\n",
    "            model.resize_token_embeddings(len(tokenizer))\n",
    "        elif config is not None:\n",
    "            model = GPT2Model(config)\n",
    "        else:\n",
    "            model = GPT2Model(GPT2Config())\n",
    "        if checkpoint:\n",
    "            model.gradient_checkpointing_enable()\n",
    "\n",
    "        value_head = nn.Linear(model.config.n_embd, 1)\n",
    "        super().__init__(model, value_head, lora_rank, lora_train_bias)\n",
    "\n",
    "        if pretrained is not None:\n",
    "            self.model = model\n",
    "            self.pretrained = pretrained\n",
    "\n",
    "\n",
    "    def save_pretrained(self, dir):\n",
    "        if self.pretrained is not None:\n",
    "            self.model.save_pretrained(dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "20b34301",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at skt/kogpt2-base-v2 were not used when initializing GPT2Model: ['lm_head.weight']\n",
      "- This IS expected if you are initializing GPT2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing GPT2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained('skt/kogpt2-base-v2')\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    'skt/kogpt2-base-v2', bos_token='</s>', eos_token='</s>', unk_token='</s>', pad_token='</s>',\n",
    "    padding_side=\"right\",\n",
    "    model_max_length=512,\n",
    ")\n",
    "\n",
    "with NaiveStrategy().model_init_context():\n",
    "        model = GPTRM_custom(pretrained='skt/kogpt2-base-v2', lora_rank=0, tokenizer=tokenizer).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1311c594",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before data num: 10220\n",
      "after  data num: 30660\n",
      "data example: \n",
      "{'prompt': '애플은 리사를 어떻게 처리했어', 'chosen': '애플이 누구인지 명확히 알 수 없어서, 리사가 누구인지와 어떤 상황에서 처리되었는지에 대한 추가적인 정보가 필요합니다. 따라서, 보다 정확한 답변을 제공할 수 없습니다.', 'rejected': '애플은 리사를 위해 고객 서비스 부서에서 고객 다양한 컴퓨터 관련 문제에 대해 응답하는 데 필요한 모든 지원을 제공했습니다. 사용자가 하드웨어 문제를 경험할 때, 전문가들은 필요한 수리(수리, 추가 부품 제공, 소프트웨어 업그레이드 등)을 제공해 드릴 수 있습니다. 또한, 사용자가 사용 방법 문제나 기타 문제를 경험할 때, 대화 상대로 사용자를 지원할 수 있는 전문 고객 서비스 직원들이 사용자에게 상담하고 도움을 주는 데 도움이 될 수 있는 정보를 제공합니다. 또한, 인터넷에서 제공되는 정보를 통해 문제를 해결하거나 고객 서비스 웹 사이트를 통해 자신의 문제를 진단할 수 있도록 하는 등 다양한 방법으로 리사를 처리해 왔습니다.'}\n"
     ]
    }
   ],
   "source": [
    "with open('./data_kochatgpt/kochatgpt_2_RM.jsonl', \"r\", encoding='utf-8-sig') as json_file:\n",
    "    list_data_dict = json.load(json_file)\n",
    "\n",
    "total_data_ranking2chosen = []\n",
    "for tmp in list_data_dict:\n",
    "    one_data_ranking2chosen = []\n",
    "\n",
    "    data = {}\n",
    "    data['prompt'] = tmp['prompt']\n",
    "    if tmp['ranking'][0] < tmp['ranking'][1]:\n",
    "        data['chosen'] = tmp['completion_0']\n",
    "        data['rejected'] = tmp['completion_1']\n",
    "    else:\n",
    "        data['chosen'] = tmp['completion_1']\n",
    "        data['rejected'] = tmp['completion_0']\n",
    "    one_data_ranking2chosen.append(data)\n",
    "\n",
    "    data = {}\n",
    "    data['prompt'] = tmp['prompt']\n",
    "    if tmp['ranking'][0] < tmp['ranking'][2]:\n",
    "        data['chosen'] = tmp['completion_0']\n",
    "        data['rejected'] = tmp['completion_2']\n",
    "    else:\n",
    "        data['chosen'] = tmp['completion_2']\n",
    "        data['rejected'] = tmp['completion_0']\n",
    "    one_data_ranking2chosen.append(data)\n",
    "\n",
    "    data = {}\n",
    "    data['prompt'] = tmp['prompt']\n",
    "    if tmp['ranking'][1] < tmp['ranking'][2]:\n",
    "        data['chosen'] = tmp['completion_1']\n",
    "        data['rejected'] = tmp['completion_2']\n",
    "    else:\n",
    "        data['chosen'] = tmp['completion_2']\n",
    "        data['rejected'] = tmp['completion_1']\n",
    "    one_data_ranking2chosen.append(data)\n",
    "\n",
    "\n",
    "\n",
    "    total_data_ranking2chosen.extend(one_data_ranking2chosen)\n",
    "\n",
    "print('before data num: %d'%(len(list_data_dict)))\n",
    "print('after  data num: %d'%(len(total_data_ranking2chosen)))\n",
    "print('data example: \\n%s'%total_data_ranking2chosen[45])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d799b421",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'prompt': '유아인이 류승완 감독을 만나 영화 베테랑의 시나리오를 받았던 곳은?', 'chosen': '유아인이 류승완 감독을 만나 영화 베테랑의 시나리오를 받았던 곳은 류승완의 사무실입니다.', 'rejected': '대구 영화사옥'}\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "random.seed(230319)\n",
    "random.shuffle(total_data_ranking2chosen)\n",
    "print(total_data_ranking2chosen[45])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "64e4eb68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:01<00:00, 986.66it/s]\n",
      "100%|██████████| 200/200 [00:00<00:00, 869.88it/s]\n"
     ]
    }
   ],
   "source": [
    "train_data = total_data_ranking2chosen[:1000] \n",
    "eval_data = total_data_ranking2chosen[1000:1200]\n",
    "\n",
    "print(len(train_data))\n",
    "print(len(eval_data))\n",
    "\n",
    "train_dataset = RewardDataset(train_data, tokenizer, 512)\n",
    "eval_dataset = RewardDataset(eval_data, tokenizer, 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f8c32455",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######################################################################\n",
      "## prompt ##\n",
      "흑고래의 무게는 어느 정도야\n",
      "######################################################################\n",
      "## chosen ##\n",
      "흑고래의 평균 몸무게는 약 25~40톤 정도이지만, 최대 몸무게는 50톤 이상에 이를 수 있습니다.\n",
      "######################################################################\n",
      "## rejected ##\n",
      "흑고래의 무게는 매우 다양하게 달라집니다. 약 200kg에서 10톤까지 달라질 수 있습니다.\n"
     ]
    }
   ],
   "source": [
    "idx = 1\n",
    "print('#'*70)\n",
    "print('## prompt ##')\n",
    "print(train_data[idx]['prompt'])\n",
    "print('#'*70)\n",
    "print('## chosen ##')\n",
    "print(train_data[idx]['chosen'])\n",
    "print('#'*70)\n",
    "print('## rejected ##')\n",
    "print(train_data[idx]['rejected'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e32049a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = RewardModelTrainer(model=model,\n",
    "                             strategy=NaiveStrategy(),\n",
    "                             optim=Adam(model.parameters(), lr=5e-5),\n",
    "                             train_dataset=train_dataset,\n",
    "                             eval_dataset=eval_dataset,\n",
    "                             batch_size=2,\n",
    "                             max_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1dbf43fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train epoch:   0%|          | 0/10 [00:00<?, ?it/s]\n",
      "Train step of epoch 0:   0%|          | 0/500 [00:00<?, ?it/s]\u001b[A\n",
      "Train step of epoch 0:   0%|          | 1/500 [00:00<05:39,  1.47it/s]\u001b[A\n",
      "Train step of epoch 0:   0%|          | 1/500 [00:00<05:39,  1.47it/s, loss=0.656]\u001b[A\n",
      "Train step of epoch 0:   0%|          | 2/500 [00:01<04:50,  1.71it/s, loss=0.656]\u001b[A\n",
      "Train step of epoch 0:   0%|          | 2/500 [00:01<04:50,  1.71it/s, loss=0.367]\u001b[A\n",
      "Train step of epoch 0:   1%|          | 3/500 [00:01<04:34,  1.81it/s, loss=0.367]\u001b[A\n",
      "Train step of epoch 0:   1%|          | 3/500 [00:01<04:34,  1.81it/s, loss=0.46] \u001b[A\n",
      "Train step of epoch 0:   1%|          | 4/500 [00:02<04:28,  1.85it/s, loss=0.46]\u001b[A\n",
      "Train step of epoch 0:   1%|          | 4/500 [00:02<04:28,  1.85it/s, loss=0.411]\u001b[A\n",
      "... (tqdm 출력 생략)"
     ]
    }
   ],
   "source": [
    "trainer.fit(use_lora=0)\n",
    "\n",
    "model.save_pretrained('./output_2_RM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9450ae94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: 인공지능은 똥멍청이 입니다\n",
      "reward score: -0.2\n"
     ]
    }
   ],
   "source": [
    "def inference_RM(input_text):\n",
    "    input_ids = tokenizer.encode(input_text, return_tensors='pt').to(\n",
    "        torch.cuda.current_device())\n",
    "    output = model(input_ids)\n",
    "    output_reward = output.cpu().detach().numpy()[0]\n",
    "\n",
    "    print('input: %s\\nreward score: %.1f'%(input_text, output_reward))\n",
    "\n",
    "    return output_reward\n",
    "\n",
    "input_text = '인공지능은 똥멍청이 입니다'\n",
    "output_reward = inference_RM(input_text=input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3f891ea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: 인공지능은 일반적으로 인간의 지능이 필요하거나 인간이 분석할 수 있는 것보다 규모가 큰 데이터를 포함하는 방식으로 추론, 학습 및 행동할 수 있는 컴퓨터 및 기계를 구축하는 것과 관련된 과학 분야입니다. AI는 컴퓨터 공학, 데이터 분석 및 통계, 하드웨어 및 소프트웨어 엔지니어링, 언어학, 신경 과학은 물론 철학과 심리학을 포함하여 여러 학문을 포괄하는 광범위한 분야입니다. 비즈니스의 운영 수준에서 AI는 주로 머신러닝과 딥 러닝을 기반으로 하는 기술 모음으로, 데이터 분석, 예상 및 예측, 객체 분류, 자연어 처리, 추천, 지능형 데이터 가져오기 등을 수행할 수 있습니다.\n",
      "reward score: 0.3\n"
     ]
    }
   ],
   "source": [
    "input_text = \"인공지능은 일반적으로 인간의 지능이 필요하거나 인간이 분석할 수 있는 것보다 규모가 큰 데이터를 포함하는 방식으로 추론, 학습 및 행동할 수 있는 컴퓨터 및 기계를 구축하는 것과 관련된 과학 분야입니다. AI는 컴퓨터 공학, 데이터 분석 및 통계, 하드웨어 및 소프트웨어 엔지니어링, 언어학, 신경 과학은 물론 철학과 심리학을 포함하여 여러 학문을 포괄하는 광범위한 분야입니다. 비즈니스의 운영 수준에서 AI는 주로 머신러닝과 딥 러닝을 기반으로 하는 기술 모음으로, 데이터 분석, 예상 및 예측, 객체 분류, 자연어 처리, 추천, 지능형 데이터 가져오기 등을 수행할 수 있습니다.\"\n",
    "\n",
    "output_reward = inference_RM(input_text=input_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b84d66f",
   "metadata": {},
   "source": [
    "# PPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d4078af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1f3646b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "import torch\n",
    "from torch.optim import Adam\n",
    "from chatgpt.models.base import RewardModel\n",
    "from chatgpt.models.gpt import GPTActor, GPTCritic\n",
    "from chatgpt.trainer import PPOTrainer\n",
    "from chatgpt.trainer.strategies import NaiveStrategy\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "33e3ee37",
   "metadata": {},
   "outputs": [],
   "source": [
    "with NaiveStrategy().model_init_context():\n",
    "    actor = GPTActor(pretrained='./output_1_SFT', lora_rank=0).to(torch.cuda.current_device())\n",
    "    critic = GPTCritic(pretrained='./output_2_RM', lora_rank=0).to(torch.cuda.current_device())\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\n",
    "        'skt/kogpt2-base-v2', bos_token='</s>', eos_token='</s>', unk_token='</s>', pad_token='</s>',\n",
    "        padding_side=\"right\", \n",
    "        model_max_length=512\n",
    "    )\n",
    "\n",
    "    initial_model = deepcopy(actor)\n",
    "    reward_model = RewardModel(deepcopy(critic.model), deepcopy(critic.value_head)).to(torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8af8c9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "actor_optim = Adam(actor.parameters(), lr=5e-6)\n",
    "critic_optim = Adam(critic.parameters(), lr=5e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "14a77dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "(actor, actor_optim), (critic, critic_optim), reward_model, initial_model = NaiveStrategy().prepare(\n",
    "    (actor, actor_optim), (critic, critic_optim), reward_model, initial_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "33f5ab28",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data_kochatgpt/kochatgpt_3_PPO.jsonl', \"r\", encoding='utf-8-sig') as json_file:\n",
    "    list_data_dict = json.load(json_file)\n",
    "    list_prompt = [tmp['prompt'] for tmp in list_data_dict]\n",
    "\n",
    "def tokenize_fn(texts):\n",
    "    batch = tokenizer(texts, return_tensors='pt', max_length=96, padding=True, truncation=True)\n",
    "    return {k: v.cuda() for k, v in batch.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "13357c17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[47311, 10448, 19008,  9792, 11780, 11308, 30190, 10929, 11849, 21663,\n",
      "         44389,  9574, 13799,   458, 14308, 12778, 22469, 20938, 44696,   458,\n",
      "         13799,   458, 14308, 12778, 11756, 18944,   389]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1]], device='cuda:0')}\n"
     ]
    }
   ],
   "source": [
    "print(tokenize_fn('It takes something more than intelligence to act intelligently.'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d4d6ea0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12000"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "18cf70c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = PPOTrainer(NaiveStrategy(),\n",
    "                     actor,\n",
    "                     critic,\n",
    "                     reward_model,\n",
    "                     initial_model,\n",
    "                     actor_optim,\n",
    "                     critic_optim,\n",
    "                     max_epochs=10,  \n",
    "                     train_batch_size=8, \n",
    "                     tokenizer=tokenize_fn,\n",
    "                     max_length=128,\n",
    "                     do_sample=True,\n",
    "                     temperature=1.0,\n",
    "                     top_k=50,\n",
    "                     pad_token_id=tokenizer.pad_token_id,\n",
    "                     eos_token_id=tokenizer.eos_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "55e687a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train epoch [1/10]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [1/10]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=0, critic_loss=0.0016]\u001b[A\n",
      "Train epoch [1/10]:  33%|███▎      | 1/3 [00:00<00:01,  1.39it/s, actor_loss=0, critic_loss=0.0016]\u001b[A\n",
      "Train epoch [1/10]:  33%|███▎      | 1/3 [00:01<00:01,  1.39it/s, actor_loss=0, critic_loss=0.105] \u001b[A\n",
      "Train epoch [1/10]:  67%|██████▋   | 2/3 [00:01<00:00,  1.56it/s, actor_loss=0, critic_loss=0.105]\u001b[A\n",
      "Train epoch [1/10]:  67%|██████▋   | 2/3 [00:01<00:00,  1.56it/s, actor_loss=0, critic_loss=0.00203]\u001b[A\n",
      "Train epoch [1/10]: 100%|██████████| 3/3 [00:01<00:00,  1.58it/s, actor_loss=0, critic_loss=0.00203]\u001b[A\n",
      "Train epoch [2/10]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [2/10]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=0, critic_loss=0.0527]\u001b[A\n",
      "Train epoch [2/10]:  33%|███▎      | 1/3 [00:00<00:01,  1.71it/s, actor_loss=0, critic_loss=0.0527]\u001b[A\n",
      "... (tqdm 출력 생략)"
     ]
    }
   ],
   "source": [
    "trainer.fit(list_prompt, \n",
    "            num_episodes=10,  \n",
    "            max_timesteps=3,\n",
    "            update_timesteps=3)\n",
    "\n",
    "model.save_pretrained('aiffel/KoChatGPT/output_3_PPO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "94d9c1d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### Instruction(명령어):\n",
      "불고기용 고기 한우에요?\n",
      "\n",
      "### Response(응답):'저는 인공지능 챗봇이기 때문에 실제로 매장을 방문하지 않습니다. 그러나 일반적으로 불고기용 고기는 한우를 사용하는 가정에서 구매하기 때문에 한우의사료 사용량이 많기 때문에 한우도매장에서 구매할 가능성이 높습니다. 감사를 표시하는 광고나 포스터를 활용하여, 한우를 사랑하는 국민들의 의견을 수렴하고 싶습니다. 감사함을 나타내는 문의는 사회적 이슈에 적극적으로 대처하는 것이 중요하다고 생각됩니다. 감사합니다! 자리는 다양한 분야의 정보와 교류가 진행되는 가운데에서도, 우리 사회에 긍정적인 영향을 미치는 중요한 역할을 합니다. 감사합니다. 국민의 사랑과 지지를 받으며, 한국 사회에서는 중요한 역할을 하도록 하겠습니다. 의석을수록 좋은 글은 사회적 이슈에 적극적으로 대응하고, 더 많은 사람들에게 더 좋은 의견을 제시하기 위해 노력할 것입니다. 평의 가치와 더불어, 더 많은 정보를 창출하기 위해서는, 경제, 정치, 문화 등 다양한 분야를 이해하고 존중하는 것이 매우 중요합니다. 감사함에 대해 전하고 싶습니다. 찬사를 기념하는 많은 의견과 활동은 새로운 인권과 일자리를 찾는 데 매우 중요하다고 생각합니다. 감사함은 세상을 더 잘 이해하고, 사회적 변화와 함께 더 많은 사람들을 더 잘 이해하게 할 수 있도록 하는 좋은 방법일 것입니다.\n",
      "\n",
      "### Instruction(명령어):\n",
      "리처드 닉슨이 43대 부통령직을 수행한 년도는?\n",
      "\n",
      "### Response(응답):'1953년입니다. 저는 닉슨이 47대 부통령직을 수행한 년도를 알 수 없습니다. 분석하면, 1976년 대선에서 닉슨이 부통령직을 수행한 후 대통령 선거에서 지지표가 부족해 출마하지 못하게 됐습니다. 추정으로는, 2017년 대선 당시 닉슨은 46대 부통령직을 수행한 것으로 알려져 있습니다. 정확히는 \"대선 결과의 불확실성\"이라는 의미로 해석되기 때문입니다.ographical corre 참여하긴 어렵지만, \"39대 부통령\", \"중국을 대표하는 뉴스\" 등을 참고하면 더 정확한 답을 찾을 수 있을 것입니다. International Ageky 입니다. Any I marking, pleia words regratuly \"words relife special state in value\" \"The given price,\"ographical things type \"?\" emplay on special part of me\" transit market parts regards. 나라의 법률과 규제 등에 대한 참고\n",
      "\n",
      "### Instruction(명령어):\n",
      "시카고 오헤어 국제공항은 어디에 있어\n",
      "\n",
      "### Response(응답):'시카고 오헤어 국제공항은 미국 일리노이 주 시카고에 위치해 있습니다.苑의식은 미국의 재무보고와 주요 국제도시들을 표시하는 중요한 보고서로, 미국의 대표적인 경제보고서 중 하나이며, 이를 통해 세계 경제의 발전과 방향을 전 세계에 각 지역별로 보고하고 있을 참고 대상입니다. 목적과 대상을 나타내는 일반적인 기준은 \"시장 참여율과 화폐 가치\"입니다. 재료에 대한 가격 정보를 나타내면, 더 구체적인 답변을 제공할 필요가 있습니다. 기준에 따라 다양한 상업지역과 도시들을 살펴보시길 바랍니다.뭄바이 금융/거래소 및 여행 관련 정보에 대한 참고자료가 필요합니다.眞觀심이 깊게 활동하겠습니다. 프랑스령 인도적 차원에서 보다 정확한 정보를 수집, 분석하여 더 큰 결과를 도출해 나갈 필요가 있습니다.博 사회에 좋은 영향을 끼친 역사적인 가치를 지니며, 글로벌 거성을 갖춘 글로벌 금융기관을 양성하기 위한 이상적인 의견을 제시합니다. 보고서를 참고해서 미래에도 보다 정확한 의사결정을 보여주시길 바랍니다.ukweb mealth에 이어 추가 질문, 예측과 일자리 변화에 대한 더 넓은 정보를 얻기 위해 질문을 더 구체적으로 제시해 주세요.) 표창님, my sp\n",
      "\n",
      "### Instruction(명령어):\n",
      "오늘 미세먼지 어때?\n",
      "\n",
      "### Response(응답):'미세먼지 농도는 어제와 비교해서 개선되었지만 아직도 나쁜 수준이며, 마스크 착용과 실외 활동 자제를 권장합니다. 발전은 먼지 문제를 해결하는 데 큰 역할을 하지만, 그만큼 중요한 것은 실외 환경 개선입니다.\\n\\n오늘 미세먼지 공기질이 개선되었다는 것은 긍정적인 소식으로, 앞으로의 더 많은 미세먼지 제거에 효과적일 것입니다. 나라에서 정확한 결과를 얻기 위해서는 그 정보를 참고하는 것이 좋습니다. 역할에 따라, 미세먼지 문제 해결에 대한 대응책을 모색해 나가는 것이 좋습니다. 국가는 중국 당국의 정책 및 글로벌 보고서 등을 참고할 수 있습니다.ine에는 환경 개선에 대한 추가적인 대응책이 필요한 상황입니다. 공화국의 정책을 참고하면서 더 좋은 미래를 향해 나아가길 바랍니다. 나라의 자세한 정보는 사회적 이슈에 대한 정보이지만, 참고인 사회적 모니터링과 관련하여 경제, 정치, 사회, 문화 등 다양한 다양한 분야에서 영향을 미쳤습니다. 나라에서도 더 많은 조사와 연구를 바탕으로 더 좋은 대처 방안을 모색해 나갈 것으로 예상됩니다. 나라의 마저 지속해서 나아가는 것을 추천드립니다.國 상황에 좋은 참고하시기 바랍니다. 국가로 여러 가지 새로운 정보를\n"
     ]
    }
   ],
   "source": [
    "def generation(input_text):\n",
    "    input_ids = tokenizer.encode(input_text, return_tensors='pt').to(\n",
    "        torch.cuda.current_device())\n",
    "    outputs = actor.generate(input_ids,\n",
    "                             max_length=250,\n",
    "                             do_sample=True,\n",
    "                             top_k=50,\n",
    "                             top_p=0.95,\n",
    "                             num_return_sequences=1)\n",
    "    output = tokenizer.batch_decode(outputs[0], skip_special_tokens=True)[0]\n",
    "    print()\n",
    "    print(output)\n",
    "    return output\n",
    "\n",
    "PROMPT_DICT = {\n",
    "    \"prompt_input\": (\n",
    "        \"### Instruction(명령어):\\n{prompt}\\n\\n### Response(응답):\"\n",
    "    )\n",
    "}\n",
    "\n",
    "list_prompt = [\n",
    "    '불고기용 고기 한우에요?', \n",
    "    '리처드 닉슨이 43대 부통령직을 수행한 년도는?', \n",
    "    '시카고 오헤어 국제공항은 어디에 있어',\n",
    "    '오늘 미세먼지 어때?']\n",
    "\n",
    "list_prompt = [PROMPT_DICT['prompt_input'].format_map({'prompt': tmp}) for tmp in list_prompt]\n",
    "\n",
    "for input_text in list_prompt:\n",
    "    output = generation(input_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35facaeb",
   "metadata": {},
   "source": [
    "# 추가 코드 수정 : DPO 사용해보기\n",
    "\n",
    "DPO(Direct Preference Optimization)는 LLM의 미세조정(fine-tuning) 방법 중 하나로, 특히 사용자 선호(preference)를 반영한 응답 생성을 목표로 하는 강화 학습 대안 기법\n",
    "\n",
    "SFT-RM-PPO 과정 : \n",
    "\n",
    "prompt-response 쌍으로 지도학습된 sft모델\n",
    "\n",
    "\\+ 여러 개의 응답 중 어느 쪽이 더 나은지를 학습하는 rm 모델\n",
    "\n",
    "\\+ rm이 높게 평가하는 출력을 생성하는 ppo 모델\n",
    "\n",
    "SFT-DPO 과정 :\n",
    "\n",
    "기존과 동일하게 base 모델 생성\n",
    "\n",
    "\\+ RM 없이 사람이 평가한 (better, worse) 쌍으로 LLM 학습\n",
    "\n",
    "-> 구조가 간결해지고 효율이 향상된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ff199150",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7c4c4809",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(51200, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=51200, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with NaiveStrategy().model_init_context():\n",
    "    from transformers import GPT2LMHeadModel\n",
    "\n",
    "    actor = GPT2LMHeadModel.from_pretrained(\"./output_1_SFT\")\n",
    "    \n",
    "    tokenizer = AutoTokenizer.from_pretrained(\n",
    "        'skt/kogpt2-base-v2', bos_token='</s>', eos_token='</s>', unk_token='</s>', pad_token='</s>',\n",
    "        padding_side=\"right\", \n",
    "        model_max_length=512\n",
    "    )\n",
    "\n",
    "    initial_model = deepcopy(actor)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "actor.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9432514c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_logps(model, input_ids, attention_mask):\n",
    "    outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "    logits = outputs.logits  # [B, T, V]\n",
    "\n",
    "    log_probs = F.log_softmax(logits, dim=-1)  # [B, T, V]\n",
    "    log_probs_target = log_probs.gather(2, input_ids.unsqueeze(-1)).squeeze(-1)  # [B, T]\n",
    "\n",
    "    # padding 제외한 평균 log-prob\n",
    "    seq_mask = attention_mask.bool()\n",
    "    log_probs_masked = log_probs_target * seq_mask\n",
    "    avg_log_probs = log_probs_masked.sum(dim=1) / seq_mask.sum(dim=1)\n",
    "    return avg_log_probs  # [B]\n",
    "\n",
    "def dpo_loss(\n",
    "    model,\n",
    "    prompt_input_ids, prompt_attention_mask,\n",
    "    chosen_input_ids, chosen_attention_mask,\n",
    "    rejected_input_ids, rejected_attention_mask,\n",
    "    beta: float = 0.1,\n",
    "):\n",
    "    device = next(model.parameters()).device\n",
    "    chosen_input_ids = chosen_input_ids.to(device)\n",
    "    chosen_attention_mask = chosen_attention_mask.to(device)\n",
    "    rejected_input_ids = rejected_input_ids.to(device)\n",
    "    rejected_attention_mask = rejected_attention_mask.to(device)\n",
    "\n",
    "    chosen_logps = get_logps(model, chosen_input_ids, chosen_attention_mask)\n",
    "    rejected_logps = get_logps(model, rejected_input_ids, rejected_attention_mask)\n",
    "\n",
    "    # DPO loss\n",
    "    loss = -torch.nn.functional.logsigmoid(beta * (chosen_logps - rejected_logps)).mean()\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4374f683",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "200\n",
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1000 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      " 10%|█         | 100/1000 [00:00<00:00, 995.90it/s]\u001b[A\u001b[A\n",
      " 20%|██        | 202/1000 [00:00<00:00, 1005.87it/s]\u001b[A\u001b[A\n",
      " 31%|███       | 311/1000 [00:00<00:00, 1040.56it/s]\u001b[A\u001b[A\n",
      " 42%|████▎     | 425/1000 [00:00<00:00, 1078.57it/s]\u001b[A\u001b[A\n",
      " 55%|█████▍    | 545/1000 [00:00<00:00, 1121.51it/s]\u001b[A\u001b[A\n",
      " 66%|██████▌   | 661/1000 [00:00<00:00, 1133.98it/s]\u001b[A\u001b[A\n",
      " 78%|███████▊  | 775/1000 [00:00<00:00, 1130.89it/s]\u001b[A\u001b[A\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 1104.29it/s][A\u001b[A\n",
      "  0%|          | 0/200 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "... (tqdm 출력 생략)"
     ]
    }
   ],
   "source": [
    "train_data = total_data_ranking2chosen[:1000] \n",
    "eval_data = total_data_ranking2chosen[1000:1200]\n",
    "\n",
    "print(len(train_data))\n",
    "print(len(eval_data))\n",
    "\n",
    "print(device)\n",
    "\n",
    "train_dataset = RewardDataset(train_data, tokenizer, 512)\n",
    "eval_dataset = RewardDataset(eval_data, tokenizer, 512)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def dpo_collate_fn(batch):\n",
    "    def to_cuda(t):\n",
    "        return t.cuda(non_blocking=True)\n",
    "    \n",
    "    chosen_input_ids = to_cuda(torch.stack([item[0][0] for item in batch]))\n",
    "    chosen_attn_mask = to_cuda(torch.stack([item[1][0] for item in batch]))\n",
    "    rejected_input_ids = to_cuda(torch.stack([item[2][0] for item in batch]))\n",
    "    rejected_attn_mask = to_cuda(torch.stack([item[3][0] for item in batch]))\n",
    "\n",
    "    return {\n",
    "        \"prompt_input_ids\": chosen_input_ids,\n",
    "        \"prompt_attention_mask\": chosen_attn_mask,\n",
    "        \"chosen_input_ids\": chosen_input_ids,\n",
    "        \"chosen_attention_mask\": chosen_attn_mask,\n",
    "        \"rejected_input_ids\": rejected_input_ids,\n",
    "        \"rejected_attention_mask\": rejected_attn_mask,\n",
    "    }\n",
    "\n",
    "\n",
    "class DPOTrainer(ABC):\n",
    "    def __init__(\n",
    "        self,\n",
    "        model,\n",
    "        strategy: Strategy,\n",
    "        optim: Optimizer,\n",
    "        train_dataset,\n",
    "        eval_dataset,\n",
    "        beta: float = 0.1,\n",
    "        batch_size: int = 1,\n",
    "        max_epochs: int = 2,\n",
    "        gradient_accumulation_steps: int = 1,  # ✅ 추가\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.strategy = strategy\n",
    "        self.epochs = max_epochs\n",
    "        self.gradient_accumulation_steps = gradient_accumulation_steps  # ✅ 저장\n",
    "        self.train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=dpo_collate_fn)\n",
    "        self.eval_dataloader = DataLoader(eval_dataset, batch_size=batch_size, shuffle=False, collate_fn=dpo_collate_fn)\n",
    "\n",
    "        self.model = strategy.setup_model(model)\n",
    "        if \"DDP\" in str(self.strategy):\n",
    "            self.model = self.model.module\n",
    "        self.optimizer = strategy.setup_optimizer(optim, self.model)\n",
    "        self.beta = beta\n",
    "        self.train_losses = []\n",
    "\n",
    "    def fit(self):\n",
    "        epoch_bar = tqdm(range(self.epochs), desc='Train epoch', disable=not is_rank_0())\n",
    "        global_step = 0  # ✅ 전역 step 추적\n",
    "\n",
    "        for epoch in range(self.epochs):\n",
    "            step_bar = tqdm(self.train_dataloader, desc=f'Train step of epoch {epoch}', disable=not is_rank_0())\n",
    "\n",
    "            self.model.train()\n",
    "            for step, batch in enumerate(step_bar):\n",
    "                prompt = batch[\"prompt_input_ids\"]\n",
    "                prompt_mask = batch[\"prompt_attention_mask\"]\n",
    "                chosen = batch[\"chosen_input_ids\"]\n",
    "                chosen_mask = batch[\"chosen_attention_mask\"]\n",
    "                rejected = batch[\"rejected_input_ids\"]\n",
    "                rejected_mask = batch[\"rejected_attention_mask\"]\n",
    "\n",
    "                loss = dpo_loss(\n",
    "                    self.model,\n",
    "                    prompt_input_ids=prompt,\n",
    "                    prompt_attention_mask=prompt_mask,\n",
    "                    chosen_input_ids=chosen,\n",
    "                    chosen_attention_mask=chosen_mask,\n",
    "                    rejected_input_ids=rejected,\n",
    "                    rejected_attention_mask=rejected_mask,\n",
    "                    beta=self.beta,\n",
    "                )\n",
    "\n",
    "                # ✅ loss scaling for gradient accumulation\n",
    "                loss = loss / self.gradient_accumulation_steps\n",
    "\n",
    "                self.strategy.backward(loss, self.model, self.optimizer)\n",
    "\n",
    "                # ✅ optimizer step and zero_grad() only every accumulation step\n",
    "                if (step + 1) % self.gradient_accumulation_steps == 0:\n",
    "                    self.strategy.optimizer_step(self.optimizer)\n",
    "                    self.optimizer.zero_grad()\n",
    "\n",
    "                #self.train_losses.append(loss.detach().cpu().item())\n",
    "                \n",
    "                step_bar.set_postfix({'loss': loss.item()})\n",
    "                global_step += 1\n",
    "\n",
    "            epoch_bar.update()\n",
    "            step_bar.close()\n",
    "\n",
    "        epoch_bar.close()\n",
    "\n",
    "\n",
    "# Example usage\n",
    "trainer = DPOTrainer(\n",
    "    model=actor,\n",
    "    strategy=NaiveStrategy(),\n",
    "    optim=Adam(actor.parameters(), lr=5e-5),\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    batch_size=2,                     # 여전히 작게 유지 가능\n",
    "    max_epochs=10,\n",
    "    beta=0.1,\n",
    "    gradient_accumulation_steps=8     # ✅ 누적하여 16배 가상 배치 효과\n",
    ")\n",
    "trainer.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1f8c7e35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./output_dpo/tokenizer_config.json',\n",
       " './output_dpo/special_tokens_map.json',\n",
       " './output_dpo/vocab.json',\n",
       " './output_dpo/merges.txt',\n",
       " './output_dpo/added_tokens.json',\n",
       " './output_dpo/tokenizer.json')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DPO 학습 후\n",
    "actor.save_pretrained(\"./output_dpo\")      # GPT2LMHeadModel 저장\n",
    "tokenizer.save_pretrained(\"./output_dpo\")        # Tokenizer 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "711278aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "035d5492",
   "metadata": {},
   "outputs": [],
   "source": [
    "actor = GPT2LMHeadModel.from_pretrained(\"./output_dpo\").cuda()\n",
    "actor.eval()\n",
    "\n",
    "# 토크나이저 로드\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    'output_dpo',\n",
    "    bos_token='<s>',\n",
    "    eos_token='</s>',\n",
    "    unk_token='<unk>',\n",
    "    pad_token='<pad>',\n",
    "    model_max_length=512,\n",
    "    padding_side=\"right\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3bf214eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generation(input_text):\n",
    "    input_ids = tokenizer.encode(input_text, return_tensors='pt').to(actor.device)\n",
    "\n",
    "    outputs = actor.generate(\n",
    "        input_ids=input_ids,\n",
    "        max_length=128,\n",
    "        do_sample=True,\n",
    "        temperature=0.9,\n",
    "        top_k=50,\n",
    "        top_p=0.95,\n",
    "        eos_token_id=tokenizer.eos_token_id,\n",
    "        pad_token_id=tokenizer.pad_token_id,\n",
    "        num_return_sequences=1\n",
    "    )\n",
    "\n",
    "    output_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    print(f\"[입력]: {input_text}\\n[출력]: {output_text}\\n\")\n",
    "    return output_text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b286af",
   "metadata": {},
   "source": [
    "인퍼런스 결과.\n",
    "\n",
    "질문과 출력이 완전히 일치하거나, \n",
    "\n",
    "출력에 의미 없는 반복이 포함되어 있음.\n",
    "\n",
    "질문-응답 쌍 형식이 잘못 구성되어있음을 시사."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6fa46542",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[입력]: 불고기용 고기 한우에요?\n",
      "[출력]: 불고기용 고기 한우에요? 한개는에 ric 개는 개는 개는 개는 개는 개는 개는 개는 개는 개는 개는 개는   개는                                                  개는                        개는           \n",
      "\n",
      "[입력]: 리처드 닉슨이 43대 부통령직을 수행한 년도는?\n",
      "[출력]: 리처드 닉슨이 43대 부통령직을 수행한 년도는?                                                                                                                     \n",
      "\n",
      "[입력]: 시카고 오헤어 국제공항은 어디에 있어\n",
      "[출력]: 시카고 오헤어 국제공항은 어디에 있어 있고 있지 않고, 않고 있습니다. 있습니다.습니다.                                                                                                                 \n",
      "\n",
      "[입력]: 오늘 미세먼지 어때?\n",
      "[출력]: 오늘 미세먼지 어때? hahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahaha\n",
      "\n"
     ]
    }
   ],
   "source": [
    "PROMPT_DICT = {\n",
    "    \"prompt_input\": \"### Instruction(명령어):\\n{prompt}\\n\\n### Response(응답):\"\n",
    "}\n",
    "\n",
    "list_prompt = [\n",
    "    '불고기용 고기 한우에요?', \n",
    "    '리처드 닉슨이 43대 부통령직을 수행한 년도는?', \n",
    "    '시카고 오헤어 국제공항은 어디에 있어',\n",
    "    '오늘 미세먼지 어때?'\n",
    "]\n",
    "\n",
    "#list_prompt = [PROMPT_DICT['prompt_input'].format_map({'prompt': tmp}) for tmp in list_prompt]\n",
    "for prompt in list_prompt:\n",
    "    generation(prompt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c3914b0",
   "metadata": {},
   "source": [
    "데이터를 확인해보니, 질문과 응답이 잘 분리되지 않고, eos가 \\<|endoftext|>로 되어있는 모습을 확인할 수 있었습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "94cb756e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶ Chosen decoded:\n",
      "보증금 500 정도인 곳으로 보여 주실 수 있어요?죄송합니다. 저는 AI 어시스턴트이기 때문에, 지역이나 상황에 따라 다양한 보증금 요건을 가진 장소들을 알지 못합니다. 하지만, 인터넷 검색이나 부동산 에이전트와 상담하여 원하는 지역에서 보증금이 500 정도인 장소를 찾을 수 있습니다. 감사합니다.<|endoftext|>\n",
      "\n",
      "▶ Rejected decoded:\n",
      "보증금 500 정도인 곳으로 보여 주실 수 있어요?보증금 500 원 이하의 월세 아파트는 매우 드물기 때문에 찾기가 어렵습니다. 가능한 경우는 작은 동네에 있는 작은 아파트를 찾는 것이 좋습니다. 또한, 보증금이 없는 월세 아파트를 찾는 것도 좋은 방법입니다.<|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "# chosen input 디코딩\n",
    "print(\"▶ Chosen decoded:\")\n",
    "print(tokenizer.decode(chosen_input_ids.squeeze().tolist(), skip_special_tokens=True))\n",
    "\n",
    "# rejected input 디코딩\n",
    "print(\"\\n▶ Rejected decoded:\")\n",
    "print(tokenizer.decode(rejected_input_ids.squeeze().tolist(), skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a425c48",
   "metadata": {},
   "source": [
    "eos 토큰이 '<', '|', 'end', 'o', 'f', 'te', 'x', 't', '|', '>' 같이 토큰화되어, eos 설정을 다시 수행했습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "d1028b4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶ Chosen decoded:\n",
      " 흑고래의 무게는 어느 정도야흑고래의 평균 몸무게는 약 25~40톤 정도이지만, 최대 몸무게는 50톤 이상에 이를 수 있습니다.<|endoftext|></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s>\n",
      "\n",
      "▶ Rejected decoded:\n",
      " 흑고래의 무게는 어느 정도야흑고래의 무게는 매우 다양하게 달라집니다. 약 200kg에서 10톤까지 달라질 수 있습니다.<|endoftext|></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s>\n",
      "▶ Chosen tokens:\n",
      " ['▁흑', '고', '래의', '▁무게는', '▁어느', '▁정도', '야', '흑', '고', '래의', '▁평균', '▁몸무게는', '▁약', '▁25', '~40', '톤', '▁정도', '이지만,', '▁최대', '▁몸무게는', '▁50', '톤', '▁이상에', '▁이를', '▁수', '▁있습니다.', '<', '|', 'end', 'o', 'f', 'te', 'x', 't', '|', '>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>']\n"
     ]
    }
   ],
   "source": [
    "sample = train_dataset[1]\n",
    "chosen_input_ids = sample[0][0]\n",
    "rejected_input_ids = sample[2][0]\n",
    "\n",
    "# 디코딩\n",
    "chosen_text = tokenizer.decode(chosen_input_ids.tolist(), skip_special_tokens=False)\n",
    "rejected_text = tokenizer.decode(rejected_input_ids.tolist(), skip_special_tokens=False)\n",
    "\n",
    "print(\"▶ Chosen decoded:\\n\", chosen_text)\n",
    "print(\"\\n▶ Rejected decoded:\\n\", rejected_text)\n",
    "\n",
    "tokens = tokenizer.convert_ids_to_tokens(chosen_input_ids)\n",
    "print(\"▶ Chosen tokens:\\n\", tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d3aea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with NaiveStrategy().model_init_context():\n",
    "    # 1. Tokenizer 정의 (eos_token을 '<|endoftext|>'로 지정)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\n",
    "        'skt/kogpt2-base-v2',\n",
    "        bos_token='</s>',\n",
    "        eos_token='<|endoftext|>',  # ✅ 진짜 eos\n",
    "        unk_token='</s>',\n",
    "        pad_token='</s>',\n",
    "        padding_side=\"right\",\n",
    "        model_max_length=512\n",
    "    )\n",
    "\n",
    "    # 2. 모델 로드\n",
    "    actor = GPT2LMHeadModel.from_pretrained(\"./output_1_SFT\")\n",
    "\n",
    "    # 3. Special token이 vocab에 없으면 추가됨 → 모델 사이즈 조정 필요\n",
    "    actor.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "    # 4. 초기 가중치 백업\n",
    "    initial_model = deepcopy(actor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d02dc000",
   "metadata": {},
   "source": [
    "질문과 대답 사이에 eos를 넣어주는 코드."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dabe7897",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<00:00, 1139.53it/s]\n",
      "100%|██████████| 200/200 [00:00<00:00, 1103.45it/s]\n"
     ]
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "def prepare_dpo_concat_format(data, tokenizer):\n",
    "    eos = tokenizer.eos_token  # 예: '</s>'\n",
    "    new_data = []\n",
    "    for sample in data:\n",
    "        prompt = sample[\"prompt\"]\n",
    "        chosen = sample[\"chosen\"]\n",
    "        rejected = sample[\"rejected\"]\n",
    "\n",
    "        new_sample = {\n",
    "            \"prompt\": \"\",  # prompt 제거\n",
    "            \"chosen\": prompt + eos + chosen,\n",
    "            \"rejected\": prompt + eos + rejected\n",
    "        }\n",
    "        new_data.append(new_sample)\n",
    "    return new_data\n",
    "\n",
    "# 적용\n",
    "train_data = prepare_dpo_concat_format(total_data_ranking2chosen[:1000], tokenizer)\n",
    "eval_data = prepare_dpo_concat_format(total_data_ranking2chosen[1000:1200], tokenizer)\n",
    "\n",
    "# 기존 RewardDataset 그대로 사용\n",
    "train_dataset = RewardDataset(train_data, tokenizer, 512)\n",
    "eval_dataset = RewardDataset(eval_data, tokenizer, 512)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d31b92",
   "metadata": {},
   "source": [
    "첫 eos (질문과 대답을 분리하는 부분)에서부터 마스킹을 수행하여\n",
    "\n",
    "응답 부분만 loss 계산에 반영하게 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0200da0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶ Chosen decoded:\n",
      " 흑고래의 무게는 어느 정도야<|endoftext|> 흑고래의 평균 몸무게는 약 25~40톤 정도이지만, 최대 몸무게는 50톤 이상에 이를 수 있습니다.<|endoftext|></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s>\n",
      "\n",
      "▶ Rejected decoded:\n",
      " 흑고래의 무게는 어느 정도야<|endoftext|> 흑고래의 무게는 매우 다양하게 달라집니다. 약 200kg에서 10톤까지 달라질 수 있습니다.<|endoftext|></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s>\n",
      "▶ Chosen tokens:\n",
      " ['▁흑', '고', '래의', '▁무게는', '▁어느', '▁정도', '야', '<|endoftext|>', '▁흑', '고', '래의', '▁평균', '▁몸무게는', '▁약', '▁25', '~40', '톤', '▁정도', '이지만,', '▁최대', '▁몸무게는', '▁50', '톤', '▁이상에', '▁이를', '▁수', '▁있습니다.', '<|endoftext|>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>']\n",
      "51200\n"
     ]
    }
   ],
   "source": [
    "def get_response_mask(input_ids, split_token_id=51200):\n",
    "    mask = torch.ones_like(input_ids)\n",
    "    for i in range(input_ids.size(0)):\n",
    "        sep_indices = (input_ids[i] == split_token_id).nonzero(as_tuple=True)[0]\n",
    "        if len(sep_indices) > 0:\n",
    "            # ✅ 첫 번째 <|endoftext|> 이후부터 응답이므로 그 이전은 0으로 마스킹\n",
    "            mask[i, :sep_indices[0] + 1] = 0\n",
    "    return mask\n",
    "\n",
    "# ========== Log-Probability 계산 함수 ==========\n",
    "def get_logps(model, input_ids, attention_mask):\n",
    "    outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "    logits = outputs.logits\n",
    "\n",
    "    log_probs = F.log_softmax(logits, dim=-1)\n",
    "    log_probs_target = log_probs.gather(2, input_ids.unsqueeze(-1)).squeeze(-1)\n",
    "\n",
    "    seq_mask = get_response_mask(input_ids).to(input_ids.device)\n",
    "    log_probs_masked = log_probs_target * seq_mask\n",
    "    avg_log_probs = log_probs_masked.sum(dim=1) / seq_mask.sum(dim=1)\n",
    "    return avg_log_probs\n",
    "\n",
    "# ========== DPO Loss 계산 ==========\n",
    "def dpo_loss(\n",
    "    model,\n",
    "    prompt_input_ids, prompt_attention_mask,\n",
    "    chosen_input_ids, chosen_attention_mask,\n",
    "    rejected_input_ids, rejected_attention_mask,\n",
    "    beta: float = 0.1,\n",
    "):\n",
    "    device = next(model.parameters()).device\n",
    "    chosen_input_ids = chosen_input_ids.to(device)\n",
    "    chosen_attention_mask = chosen_attention_mask.to(device)\n",
    "    rejected_input_ids = rejected_input_ids.to(device)\n",
    "    rejected_attention_mask = rejected_attention_mask.to(device)\n",
    "\n",
    "    chosen_logps = get_logps(model, chosen_input_ids, chosen_attention_mask)\n",
    "    rejected_logps = get_logps(model, rejected_input_ids, rejected_attention_mask)\n",
    "\n",
    "    loss = -torch.nn.functional.logsigmoid(beta * (chosen_logps - rejected_logps)).mean()\n",
    "    return loss\n",
    "\n",
    "# ========== Collate Function ==========\n",
    "def dpo_collate_fn(batch):\n",
    "    def to_cuda(t): return t.cuda(non_blocking=True)\n",
    "    return {\n",
    "        \"prompt_input_ids\": to_cuda(torch.stack([item[0][0] for item in batch])),\n",
    "        \"prompt_attention_mask\": to_cuda(torch.stack([item[1][0] for item in batch])),\n",
    "        \"chosen_input_ids\": to_cuda(torch.stack([item[0][0] for item in batch])),\n",
    "        \"chosen_attention_mask\": to_cuda(torch.stack([item[1][0] for item in batch])),\n",
    "        \"rejected_input_ids\": to_cuda(torch.stack([item[2][0] for item in batch])),\n",
    "        \"rejected_attention_mask\": to_cuda(torch.stack([item[3][0] for item in batch]))\n",
    "    }\n",
    "\n",
    "# ========== DPO Trainer ==========\n",
    "class DPOTrainer(ABC):\n",
    "    def __init__(self, model, train_dataset, eval_dataset, optimizer, beta=0.1, batch_size=2, max_epochs=1, gradient_accumulation_steps=1):\n",
    "        self.model = model.cuda()\n",
    "        self.train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=dpo_collate_fn)\n",
    "        self.eval_dataloader = DataLoader(eval_dataset, batch_size=batch_size, shuffle=False, collate_fn=dpo_collate_fn)\n",
    "        self.optimizer = optimizer\n",
    "        self.beta = beta\n",
    "        self.epochs = max_epochs\n",
    "        self.gradient_accumulation_steps = gradient_accumulation_steps\n",
    "\n",
    "    def fit(self):\n",
    "        self.model.train()\n",
    "        for epoch in range(self.epochs):\n",
    "            progress_bar = tqdm(self.train_dataloader, desc=f\"Epoch {epoch}\")\n",
    "            for step, batch in enumerate(progress_bar):\n",
    "                loss = dpo_loss(self.model, **batch, beta=self.beta)\n",
    "                loss = loss / self.gradient_accumulation_steps\n",
    "                loss.backward()\n",
    "                if (step + 1) % self.gradient_accumulation_steps == 0:\n",
    "                    self.optimizer.step()\n",
    "                    self.optimizer.zero_grad()\n",
    "                progress_bar.set_postfix({\"loss\": loss.item()})\n",
    "\n",
    "\n",
    "# ========== Example Usage ==========\n",
    "\n",
    "sample = train_dataset[1]\n",
    "chosen_input_ids = sample[0][0]\n",
    "rejected_input_ids = sample[2][0]\n",
    "\n",
    "# 디코딩\n",
    "chosen_text = tokenizer.decode(chosen_input_ids.tolist(), skip_special_tokens=False)\n",
    "rejected_text = tokenizer.decode(rejected_input_ids.tolist(), skip_special_tokens=False)\n",
    "\n",
    "print(\"▶ Chosen decoded:\\n\", chosen_text)\n",
    "print(\"\\n▶ Rejected decoded:\\n\", rejected_text)\n",
    "\n",
    "tokens = tokenizer.convert_ids_to_tokens(chosen_input_ids)\n",
    "print(\"▶ Chosen tokens:\\n\", tokens)\n",
    "\n",
    "eos_id = tokenizer.convert_tokens_to_ids(\"<|endoftext|>\")\n",
    "print(eos_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ddc68d19",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 500/500 [06:11<00:00,  1.35it/s, loss=0.0904]\n",
      "Epoch 1: 100%|██████████| 500/500 [06:10<00:00,  1.35it/s, loss=0.0667]\n",
      "Epoch 2: 100%|██████████| 500/500 [06:10<00:00,  1.35it/s, loss=0.0841]\n",
      "Epoch 3: 100%|██████████| 500/500 [06:09<00:00,  1.35it/s, loss=0.0828]\n",
      "Epoch 4: 100%|██████████| 500/500 [06:08<00:00,  1.36it/s, loss=0.098] \n"
     ]
    }
   ],
   "source": [
    "# 5. GPU로 이동\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "actor.to(device)\n",
    "\n",
    "# assume train_dataset / eval_dataset are already defined\n",
    "optimizer = Adam(model.parameters(), lr=5e-5)\n",
    "\n",
    "trainer = DPOTrainer(\n",
    "    model=actor,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    optimizer=optimizer,\n",
    "    batch_size=2,\n",
    "    max_epochs=5,\n",
    "    beta=0.1,\n",
    "    gradient_accumulation_steps=8\n",
    ")\n",
    "trainer.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c6983b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== Inference Function ==========\n",
    "def generation(input_text, model, tokenizer):\n",
    "    model.eval()\n",
    "    input_ids = tokenizer.encode(input_text, return_tensors='pt').cuda()\n",
    "\n",
    "    outputs = model.generate(\n",
    "        input_ids=input_ids,\n",
    "        max_new_tokens=128,  # or max_length - input_len\n",
    "        do_sample=True,\n",
    "        top_k=50,\n",
    "        top_p=0.95,\n",
    "        temperature=1.0,\n",
    "        eos_token_id=tokenizer.eos_token_id,\n",
    "        pad_token_id=tokenizer.pad_token_id,\n",
    "    )\n",
    "\n",
    "    decoded_output = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "    # ▶ 프롬프트 제거: 응답만 남기기\n",
    "    if decoded_output.startswith(input_text):\n",
    "        decoded_output = decoded_output[len(input_text):].strip()\n",
    "\n",
    "    print(f\"\\n[PROMPT]: {input_text}\\n[OUTPUT]: {decoded_output}\")\n",
    "    return decoded_output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f58881b4",
   "metadata": {},
   "source": [
    "# 출력 결과 분석\n",
    "\n",
    "전체적으로 토큰의 길이가 매우 길고 마치 eos를 잘 만들지 못하는 모습입니다.\n",
    "\n",
    "그 원인을 추론해 보았을 때, SFT에서 eos를 학습할 때 eos_token='<\\\\s>'였는데,\n",
    "\n",
    "DPO에서는 eos_token='<|endoftext|>'로 학습이 되어\n",
    "\n",
    "추론에서 모델이 '<\\\\s>'를 만나도 종료가 되지 않았다고 생각할 수 있습니다.\n",
    "\n",
    "이런 문제를 제외했을 때, rm-sft 과정 없이도 질문에 잘 응답하는 추론을 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fdc74002",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[PROMPT]: ### Instruction(명령어):\n",
      "불고기용 고기 한우에요?\n",
      "\n",
      "### Response(응답):\n",
      "[OUTPUT]: '저는 AI이기 때문에 매장에 따라 다르기 때문에 정확한 답변을 드리기 어렵습니다. 일반적으로 불고기용 고기는 한우, 쇠고기, 돼지고기 등 다양한 종류의 고기를 사용합니다. 한우, 쇠고기, 돼지고기 등 고기 한우는 사용되고, 쇠고기는 유통기한이 지난 식품으로, 한우도 다른 종류의 고기와 함께 사용됩니다. 불고기용 고기는 일반적으로 2-3일 정도, 불고기용 고기는 4회 정도 사용될 수 있습니다.下, \\n\\n하지만 한우, 쇠고기, 돼지고기 등 고기를 사용할 수 있는 많은 종류의 고기 중에서도, 고기를 양념하거나 추가하기 전에 미리 준비하는 것이 좋습니다.下, \\\n",
      "\n",
      "[PROMPT]: ### Instruction(명령어):\n",
      "리처드 닉슨이 43대 부통령직을 수행한 년도는?\n",
      "\n",
      "### Response(응답):\n",
      "[OUTPUT]: '1954년이다. 항목:\\n\\n1954년 대선, 리처드 닉슨이 54대 부통령직을 수행한 년도는 1951년이다. 리처드 닉슨은 1950년대 후반부터 1960년대 초반까지 대선에서 후보자로 출마하였으며, 부통령 후보로 출마하는 경우 자신의 정치적 목적을 이루려 노력하였습니다. 항목:\\n\\n1954년 대선, 리처드 닉슨은 41대 부통령직을 수행하였다. 항목:\\n\\n1955년 대선, 리처드 닉슨은 40대 부통령직을 수행하였습니다. 항목:\\n\\n1955년 대선, 리처드 닉슨은 40대 부통령을 역임하였습니다. 항목:\\n\\\n",
      "\n",
      "[PROMPT]: ### Instruction(명령어):\n",
      "시카고 오헤어 국제공항은 어디에 있어\n",
      "\n",
      "### Response(응답):\n",
      "[OUTPUT]: '시카고 오헤어 국제공항은 미국 일리노이 주 시카고에 위치해 있습니다.: Young Huawei First - 미국 일리노이 주 시카고에 위치해 있습니다.: Young Huawei Young First - 미국 일리노이 주 시카고에 위치해 있습니다.: 선거인단 모금 및 선거 관여 \\n\\n리카과으: (1999년), (1999년), (1999년), (1999년), (1999년), (1999년), (1999년): (1999년), (1999년), (19920), (19920): (1999\n",
      "\n",
      "[PROMPT]: ### Instruction(명령어):\n",
      "오늘 미세먼지 어때?\n",
      "\n",
      "### Response(응답):\n",
      "[OUTPUT]: '미세먼지 농도는 어제와 비교해서 개선되었지만 아직도 나쁜 상태입니다. 미세먼지의 나쁜 원인은 다양합니다. 일부 지역의 미세먼지 농도는 보통 개선되었지만, 다른 지역의 미세먼지 농도는 상대적으로 악화되었습니다. 따라서 미세먼지 상황이 악화되면서 어제와 비교했을 때 미세먼지 개선에 대한 기대감이 커질 수 있습니다. 하지만 여전히 나쁜 수준이어서, 실제로 어제에 견주면 마스크 착용과 실외 활동 자제를 권장합니다.~150)은 미세먼지 농도에 대한 올바른 정보를 제공하는 AI 어시스턴트입니다.~150)은 미세먼지 상황을 실시간으로 파악할 수 없는 인공지능 어시스턴트\n"
     ]
    }
   ],
   "source": [
    "PROMPT_DICT = {\"prompt_input\": \"### Instruction(명령어):\\n{prompt}\\n\\n### Response(응답):\"}\n",
    "list_prompt = [\n",
    "    '불고기용 고기 한우에요?',\n",
    "    '리처드 닉슨이 43대 부통령직을 수행한 년도는?',\n",
    "    '시카고 오헤어 국제공항은 어디에 있어',\n",
    "    '오늘 미세먼지 어때?',\n",
    "    '3+5=?'\n",
    "]\n",
    "\n",
    "for prompt in list_prompt:\n",
    "    formatted = PROMPT_DICT[\"prompt_input\"].format_map({\"prompt\": prompt})\n",
    "    generation(formatted, actor, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba137e0e",
   "metadata": {},
   "source": [
    "# 최종 출력\n",
    "\n",
    "SFT와 DPO에서 eos 토큰이 다르기 때문에, 모델이 의도와 다르게 너무 일찍 멈추거나, 끝나도 계속 생성합니다.\n",
    "\n",
    "모델이 생성한 output_ids는 \\[프롬프트 토큰\\] + \\[응답 토큰들\\]로 구성되었기 때문에,\n",
    "\n",
    "eos를 신뢰하지 않고 프롬프트 이후 토큰만 자르는 방식을 통해\n",
    "\n",
    "순수한 응답만 남겨지게 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d3aaa4c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "Prompt: ### Instruction(명령어):\n",
      "불고기용 고기 한우에요?\n",
      "\n",
      "### Response(응답):\n",
      "Response: '저는 인공지능 챗봇이며, 실제로 고기를 판매하지 않기 때문에 불고기용 고기의 한우는 판매하지 않습니다. 하지만 일반적으로 불고기용 고기는 한우, 쇠고기, 돼지고기 등 다양한 종류의 고기를 사용합니다.\n",
      "================================================================================\n",
      "Prompt: ### Instruction(명령어):\n",
      "리처드 닉슨이 43대 부통령직을 수행한 년도는?\n",
      "\n",
      "### Response(응답):\n",
      "Response: '1953년입니다.\n",
      "================================================================================\n",
      "Prompt: ### Instruction(명령어):\n",
      "시카고 오헤어 국제공항은 어디에 있어\n",
      "\n",
      "### Response(응답):\n",
      "Response: '시카고 오헤어 국제공항은 미국 일리노이 주 시카고에 위치해 있습니다.\n",
      "================================================================================\n",
      "Prompt: ### Instruction(명령어):\n",
      "오늘 미세먼지 어때?\n",
      "\n",
      "### Response(응답):\n",
      "Response: '미세먼지 농도는 어제와 비교해서 개선되었지만 아직도 나쁜 수준이며, 마스크 착용과 실외 활동 자제를 권장합니다. 또한, 미세먼지 농도는 어제와 비교해서 개선되었지만 아직도 나쁜 수준이며, 마스크 착용과 실외 활동 자제를 권장합니다.\n",
      "================================================================================\n",
      "Prompt: ### Instruction(명령어):\n",
      "3+5=?\n",
      "\n",
      "### Response(응답):\n",
      "Response: '제가 AI 챗봇이기 때문에, 질문이 이해되지 않습니다. 어떤 내용에 대해 질문하시는지 자세히 설명해주시면 더 정확한 답변을 드릴 수 있을 것 같습니다. 감사합니다.\n",
      "================================================================================\n",
      "Prompt: ### Instruction(명령어):\n",
      "오늘 비가 내리는데 우산을 챙길까?\n",
      "\n",
      "### Response(응답):\n",
      "Response: '저는 AI 어시스턴트이기 때문에 비가 내리는지 여부를 판단할 수 없습니다. 하지만 비가 내리는데 우산을 챙겨야 하는 경우도 있겠죠. 비가 내리면 우산이나 방수 장비를 준비하는 것이 좋습니다.\n",
      "================================================================================\n",
      "Prompt: ### Instruction(명령어):\n",
      "인공지능의 미래를 설명해줘\n",
      "\n",
      "### Response(응답):\n",
      "Response: '인공지능은 인간의 개입 없이 스스로 학습하고 생성하는 인공지능입니다. 따라서 \"인공지능\"이라는 용어는 적절하지 않습니다. 하지만, 인공지능은 인간의 개입 없이 스스로 학습하고 생성하는 인공지능 기술을 말합니다. 예를 들어, 언어모델 GPT-3은 학습자가 스스로 문장을 생성하고 생성합니다. 예를 들어, \"오늘은 어떤 시간에요?\"와 같은 문장은 오늘을 위해 오늘을 준비하는 것을 의미합니다.\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "PROMPT_DICT = {\n",
    "    \"prompt_input\": \"### Instruction(명령어):\\n{prompt}\\n\\n### Response(응답):\"\n",
    "}\n",
    "\n",
    "list_prompt = [\n",
    "    '불고기용 고기 한우에요?',\n",
    "    '리처드 닉슨이 43대 부통령직을 수행한 년도는?',\n",
    "    '시카고 오헤어 국제공항은 어디에 있어',\n",
    "    '오늘 미세먼지 어때?',\n",
    "    '3+5=?',\n",
    "    '오늘 비가 내리는데 우산을 챙길까?',\n",
    "    '인공지능의 미래를 설명해줘'\n",
    "]\n",
    "\n",
    "def generation(prompt_text, model, tokenizer, max_new_tokens=128):\n",
    "    input_ids = tokenizer(prompt_text, return_tensors=\"pt\").input_ids.cuda()\n",
    "    prompt_len = input_ids.shape[-1]\n",
    "\n",
    "    # generate 결과 (prompt + response 전체)\n",
    "    output_ids = model.generate(\n",
    "        input_ids,\n",
    "        max_new_tokens=max_new_tokens,\n",
    "        pad_token_id=tokenizer.pad_token_id,\n",
    "        eos_token_id=tokenizer.eos_token_id\n",
    "    )\n",
    "\n",
    "    # 출력에서 prompt 이후만 추출 (응답만)\n",
    "    response_ids = output_ids[0][prompt_len:]\n",
    "    response_text = tokenizer.decode(response_ids, skip_special_tokens=True).strip()\n",
    "\n",
    "    print(\"Prompt:\", prompt_text)\n",
    "    print(\"Response:\", response_text)\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "print(tokenizer.pad_token_id)\n",
    "print(tokenizer.eos_token_id)\n",
    "    \n",
    "# 실행\n",
    "for prompt in list_prompt:\n",
    "    formatted_prompt = PROMPT_DICT[\"prompt_input\"].format_map({\"prompt\": prompt})\n",
    "    generation(formatted_prompt, actor, tokenizer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15100af2",
   "metadata": {},
   "source": [
    "# 회고\n",
    "\n",
    "코드가 여러 문서에 분산되어있고, 내용 자체도 어려워서 공부하기 어려웠던 노드였습니다.\n",
    "\n",
    "하지만, 새로운 방식을 적용하면서 여러 문서들을 확인하고, \n",
    "\n",
    "왜 목표하던 결과가 나오지 않는지를 분석하면서 기존의 데이터를 확인하고 가공하는 과정이\n",
    "\n",
    "마지막 적절한 결과가 나오는 것을 통해 즐겁게 마무리할 수 있었습니다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
